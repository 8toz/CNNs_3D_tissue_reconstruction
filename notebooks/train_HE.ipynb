{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "execution_time = pd.Timestamp.now()\n",
    "\n",
    "\n",
    "TRAIN_CONFIG = {\n",
    "    \"training_path\":\"./data/final_images/train\",\n",
    "    \"validation_path\":\"./data/final_images/validation\", \n",
    "    \"test_path\":\"./data/final_images/test\",\n",
    "    \"network\":\"unet_pluplus\", # valid network: unet, deeplabv3, attention_unet, attention_resunet, unet_pluplus\n",
    "    \"save_model\":True,\n",
    "    \"downscaling_factor\":32, #If specified you can keep track of performance in the excel file\n",
    "    \"n_classes\":5,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 1,\n",
    "    \"validation_split\":0.2,\n",
    "    \"test_split\":0.1,\n",
    "    \"learning_rate\":0.001,\n",
    "    \"early_stopping_patience\":50,\n",
    "    \"lr_on_plateau_patience\":25,\n",
    "    \"lr_mod_factor\":0.1,\n",
    "    \"execution_time\": execution_time.strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    \"results_folder\": \"results_\" + execution_time.strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    \"verbose\": 1 if os.name==\"nt\" else 0 # dissables verbose if we run on Snellius\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the labels from its corresponding label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.generate_training_labels(images_path=\"./data/66-4/\"\n",
    "                               , labels_path=\"./data/GeoJson\"\n",
    "                               , resolution=32\n",
    "                               , validation_split=TRAIN_CONFIG[\"validation_split\"]\n",
    "                               , test_split=TRAIN_CONFIG[\"test_split\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds mossaics with image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.build_mossaic(labels_source_directory=\"./data/train_labels\" \n",
    "                    , mossaic_destination_directory=\"./data/mossaics/training_mossaics\"\n",
    "                    , matrix_size=1024\n",
    "                    , data_augmentation=False\n",
    "                    , patchify_large_labels=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.build_mossaic(labels_source_directory=\"./data/validation_labels\" \n",
    "                    , mossaic_destination_directory=\"./data/mossaics/validation_mossaics\"\n",
    "                    , matrix_size=1024\n",
    "                    , data_augmentation=False\n",
    "                    , patchify_large_labels=True\n",
    "                    )\n",
    "\n",
    "utils.build_mossaic(labels_source_directory=\"./data/test_labels\"\n",
    "                    , mossaic_destination_directory=\"./data/mossaics/test_mossaics\"\n",
    "                    , matrix_size=1024\n",
    "                    , data_augmentation=False\n",
    "                    , patchify_large_labels=True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slices the mossaics into the desired size for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.prepare_training_images(mossaic_directory=\"./data/mossaics/training_mossaics\"\n",
    "                              , destination_directory= \"./data/final_images/train\"\n",
    "                              , slice_size=(128, 128)\n",
    "                              , desired_background_color = [240, 239, 241]\n",
    "                              , tolerance=0.05)\n",
    "\n",
    "utils.prepare_training_images(mossaic_directory=\"./data/mossaics/validation_mossaics\"\n",
    "                              , destination_directory= \"./data/final_images/validation\"\n",
    "                              , slice_size=(128, 128)\n",
    "                              , desired_background_color = [240, 239, 241]\n",
    "                              , tolerance=0.05)\n",
    "\n",
    "utils.prepare_training_images(mossaic_directory=\"./data/mossaics/test_mossaics\"\n",
    "                              , destination_directory= \"./data/final_images/test\"\n",
    "                              , slice_size=(128, 128)\n",
    "                              , desired_background_color = [240, 239, 241]\n",
    "                              , tolerance=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_time = pd.Timestamp.now()\n",
    "\n",
    "test_set = [50, 100, 200, 300]\n",
    "networks = [\"unet\", \"deeplabv3\", \"attention_unet\", \"attention_resunet\", \"unet_pluplus\"]\n",
    "\n",
    "# for i in range(len(test_set)):\n",
    "#     print(f\"Testing {test_set[i]} epochs\")\n",
    "#     for network in networks:\n",
    "TRAIN_CONFIG = {\n",
    "    \"training_path\":\"./data/final_images/train\",\n",
    "    \"validation_path\":\"./data/final_images/validation\", \n",
    "    \"test_path\":\"./data/final_images/test\",\n",
    "    \"network\":\"unet\",\n",
    "    \"save_model\":True,\n",
    "    \"downscaling_factor\":32, #If specified you can keep track of performance in the excel file\n",
    "    \"n_classes\":5,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 1000,\n",
    "    \"validation_split\":0.1,\n",
    "    \"test_split\":0.1,\n",
    "    \"learning_rate\":0.001,\n",
    "    \"early_stopping_patience\":10,\n",
    "    \"lr_on_plateau_patience\":11,\n",
    "    \"lr_mod_factor\":0.1,\n",
    "    \"execution_time\": execution_time.strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    \"results_folder\": \"results_\" + execution_time.strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    \"verbose\": 1 if os.name==\"nt\" else 0 # dissables verbose if we run on Snellius\n",
    "}\n",
    "utils.train_model(TRAIN_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from natsort import natsorted\n",
    "import re\n",
    "import shutil\n",
    "import skimage\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "os.environ[\"OPENCV_IO_MAX_result_PIXELS\"] = pow(2,40).__str__()\n",
    "\n",
    "import cv2\n",
    "\n",
    "def split_label_dims(img_path):\n",
    "    img = cv2.imread(img_path,0)\n",
    "    final_image = np.zeros_like(img)\n",
    "\n",
    "    for value in [1, 2, 3, 4]:\n",
    "        single_channel_img = np.where(img == value, 1, 0)\n",
    "        final_image = np.dstack((final_image, single_channel_img))\n",
    "\n",
    "\n",
    "    final_image = final_image[:, :, 1:]\n",
    "\n",
    "    return final_image\n",
    "\n",
    "def split_label_dims_highres(img):\n",
    "    final_image = np.zeros_like(img)\n",
    "\n",
    "    for value in [1, 2, 3, 4]:\n",
    "        single_channel_img = np.where(img == value, 1, 0)\n",
    "        final_image = np.dstack((final_image, single_channel_img))\n",
    "\n",
    "\n",
    "    final_image = final_image[:, :, 1:]\n",
    "\n",
    "    return final_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps for multiplex images:\n",
    "\n",
    "- Downscale to your desired resolution\n",
    "- Blend multiplex images\n",
    "- Group them in their corresponding sets\n",
    "- Align them between each other or with H&E as reference\n",
    "- Align each channel independently based on the previous output\n",
    "- Build the 3D in Napari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utils.resize_qptiff_files(\"./data/multiplex\", \"32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.blend_multiplex(\"./data/multiplex/processed_32\", invert_image=False)\n",
    "utils.group_multiplex_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Croping section (Manual Step to avoid having unnecesarily large images) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_and_save(img_path, cropping_values):\n",
    "    img = cv2.imread(img_path)\n",
    "    cropped_image = img[cropping_values[0]:cropping_values[1], cropping_values[2]:cropping_values[3]]\n",
    "    cv2.imwrite(img_path, cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the dictionary from the JSON file (manually annotated cropping regions)\n",
    "with open('./data/cropping_dict.json', 'r') as json_file:\n",
    "    cropping_dict_loaded = json.load(json_file)\n",
    "\n",
    "print(\"Cropping dictionary loaded from cropping_dict.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(\"./data/multiplex/processed_32/*.tif\")\n",
    "\n",
    "for key in cropping_dict_loaded:\n",
    "    search_key = key.split(\".\")[0]\n",
    "    cropping_values = cropping_dict_loaded[key]\n",
    "    counter = 0\n",
    "    for file in files: \n",
    "        if search_key in file:\n",
    "             crop_and_save(file, cropping_values)\n",
    "             counter += 1\n",
    "\n",
    "    assert counter == 8, \"Something went wrong images cropped should be 8\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Align and check alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After aligning shapes should be equal to the HE registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aligning for now runs in matlab\n",
    "utils.multiplex_alignment_report(\"./data/test_alignment_all_2\", verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply affine transform channel-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.apply_affine_channel_wise(dir=\"./data/multiplex/processed_32/*.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize only multiplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.visualize_multiplex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine Multiplex and HE (OOM error try reshaping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_pad_image(image, divisor=128):\n",
    "    \"\"\"\n",
    "    Pads an image with the required size to predict.\n",
    "    \"\"\"\n",
    "    # Calculate the amount of padding needed\n",
    "    height, width = image.shape[:2]\n",
    "    pad_height = (divisor - height % divisor) % divisor\n",
    "    pad_width = (divisor - width % divisor) % divisor\n",
    "\n",
    "    # Create a white canvas with the desired dimensions\n",
    "    white_canvas = np.zeros((height + pad_height, width + pad_width), dtype=np.uint8)\n",
    "\n",
    "    # Place the original image on the white canvas\n",
    "    white_canvas[:height, :width] = image\n",
    "\n",
    "    return white_canvas\n",
    "\n",
    "\n",
    "multiplex_files = glob.glob(\"./data/blended_multiplex/*.tif\")\n",
    "\n",
    "multiplex_numbers = []\n",
    "\n",
    "for file in multiplex_files: \n",
    "    multiplex_numbers.append(os.path.basename(file).split(\".\")[0]) \n",
    "\n",
    "image_slides = multiplex_numbers.copy()\n",
    "\n",
    "for path in glob.glob(\"./data/predictions/*.png\"):\n",
    "    match = re.search(r'_(\\d+)_Scan', path)\n",
    "    number = match.group(1)\n",
    "    image_slides.append(number)\n",
    "\n",
    "final_stack = {\"DAPI\":[], \"Opal_480\":[], \"Opal_520\":[], \"Opal_570\":[], \"Opal_620\":[], \"Opal_690\":[], \"Opal_780\":[], \"Sample_AF\":[], \"Stroma\":[], \"Adipocytes\":[], \"Epithelium\":[]}\n",
    "multiplex_channels = [\"DAPI\", \"Opal_480\", \"Opal_520\", \"Opal_570\", \"Opal_620\", \"Opal_690\", \"Opal_780\", \"Sample_AF\"]\n",
    "\n",
    "\n",
    "for slide in tqdm_notebook(natsorted(image_slides)):\n",
    "    if slide not in multiplex_numbers:\n",
    "        for he_path in glob.glob(\"./data/predictions/*.png\"):\n",
    "            if slide in he_path:\n",
    "                img = split_label_dims(he_path)\n",
    "                img = np.uint8(img[:,:,0])\n",
    "                img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "                img = np.int32(img)\n",
    "                img = skimage.morphology.label(img)\n",
    "                img = skimage.morphology.remove_small_objects(img, 32)\n",
    "                img = np.where(img > 0, 1, 0)\n",
    "                \n",
    "                final_stack[\"Epithelium\"].append(img)\n",
    "                \n",
    "                img = split_label_dims(he_path)\n",
    "                img = np.uint8(img[:,:,2])\n",
    "                img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "                img = np.where(img > 0, 1, 0)\n",
    "                final_stack[\"Stroma\"].append(img)\n",
    "\n",
    "                img = split_label_dims(he_path)\n",
    "                img = np.uint8(img[:,:,3])\n",
    "                img = cv2.resize(img, (img.shape[1]//2, img.shape[0]//2))\n",
    "                img = np.where(img > 0, 1, 0)\n",
    "                final_stack[\"Adipocytes\"].append(img)\n",
    "                \n",
    "                # Include a zerolike matrix in all multiplex image \n",
    "                final_stack[\"DAPI\"].append(np.zeros_like(img))\n",
    "                final_stack[\"Opal_480\"].append(np.zeros_like(img))\n",
    "                final_stack[\"Opal_520\"].append(np.zeros_like(img))\n",
    "                final_stack[\"Opal_570\"].append(np.zeros_like(img))\n",
    "                final_stack[\"Opal_620\"].append(np.zeros_like(img))\n",
    "                final_stack[\"Opal_690\"].append(np.zeros_like(img))\n",
    "                final_stack[\"Opal_780\"].append(np.zeros_like(img))\n",
    "                final_stack[\"Sample_AF\"].append(np.zeros_like(img))\n",
    "                break\n",
    "    else:\n",
    "        for channel in multiplex_channels:\n",
    "            for file in glob.glob(\"./data/registered_multiplex/*.tif\"):\n",
    "                if channel in file and slide in file:\n",
    "                    image = cv2.imread(file, 0)\n",
    "                    padded_image = black_pad_image(image, divisor=128)\n",
    "                    padded_image = cv2.resize(padded_image, (padded_image.shape[1]//2, padded_image.shape[0]//2))\n",
    "                    final_stack[channel].append(padded_image)\n",
    "\n",
    "        final_stack[\"Stroma\"].append(np.zeros_like(padded_image))\n",
    "        final_stack[\"Adipocytes\"].append(np.zeros_like(padded_image))\n",
    "        final_stack[\"Epithelium\"].append(np.zeros_like(padded_image))\n",
    "\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "colormaps = [\"blue\", \"bop orange\", \"bop purple\", \"cyan\", \"gray\", \"green\", \"yellow\", \"magenta\", \"turbo\", \"yellow\", \"orange\"]\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "for channel, color in zip(final_stack, colormaps):\n",
    "    # print(channel)\n",
    "    stack = final_stack[channel]\n",
    "    stack = np.array(stack)\n",
    "    viewer.add_image(stack, name=channel, scale=(20,8,8), colormap=color, blending=\"additive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "for path in glob.glob(\"./test_predictions/*.png\"):\n",
    "    colors = [\"black\", \"green\", \"red\", \"blue\", \"yellow\"]\n",
    "    imin=0\n",
    "    imax=len(colors)\n",
    "    cmap = plt.cm.colors.ListedColormap(colors)\n",
    "    img = cv2.imread(path, 0)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.title(path)\n",
    "    plt.imshow(img, cmap=cmap, vmin=imin, vmax=imax,interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HE high res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import napari \n",
    "\n",
    "\n",
    "he_stack = {\"Stroma\":[], \"Adipocytes\":[], \"Epithelium\":[], \"Blood Vessels\":[]}\n",
    "he_paths = glob.glob(\"./data/bck_predictions/*.png\")\n",
    "\n",
    "for he_path in tqdm_notebook(he_paths):\n",
    "\n",
    "    img = cv2.imread(he_path,0)\n",
    "    img = cv2.resize(img, (img.shape[1]//16, img.shape[0]//16))\n",
    "\n",
    "    splitted_img = split_label_dims_highres(img)\n",
    "\n",
    "    epithelium = np.uint8(splitted_img[:,:,0])\n",
    "    epithelium = np.int32(epithelium)\n",
    "    epithelium = skimage.morphology.label(epithelium)\n",
    "    epithelium = skimage.morphology.remove_small_objects(epithelium, 64)\n",
    "    epithelium = np.where(epithelium > 0, 1, 0)\n",
    "\n",
    "    he_stack[\"Epithelium\"].append(epithelium)\n",
    "\n",
    "    bv = np.uint8(splitted_img[:,:,1])\n",
    "    bv = np.int32(bv)\n",
    "    bv = skimage.morphology.label(bv)\n",
    "    bv = skimage.morphology.remove_small_objects(bv, 64)\n",
    "    bv = np.where(bv > 0, 1, 0)\n",
    "    he_stack[\"Blood Vessels\"].append(bv)\n",
    "\n",
    "    stroma = np.uint8(splitted_img[:,:,2])\n",
    "    stroma = skimage.morphology.label(stroma)\n",
    "    stroma = skimage.morphology.remove_small_objects(stroma, 64)\n",
    "    stroma = np.where(stroma > 0, 1, 0)\n",
    "    he_stack[\"Stroma\"].append(stroma)\n",
    "\n",
    "    fat = np.uint8(splitted_img[:,:,3])\n",
    "    fat = skimage.morphology.label(fat)\n",
    "    fat = skimage.morphology.remove_small_objects(fat, 64)\n",
    "    fat = np.where(fat > 0, 1, 0)\n",
    "    he_stack[\"Adipocytes\"].append(fat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "\n",
    "colormaps = [\"blue\", \"yellow\", \"green\", \"red\"]\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "for channel, color in zip(he_stack, colormaps):\n",
    "    # print(channel)\n",
    "    stack = he_stack[channel]\n",
    "    stack = np.array(stack)\n",
    "    viewer.add_image(stack, name=channel, scale=(20,8,8), colormap=color, blending=\"additive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_small_objects(img):\n",
    "        binary = np.copy(img)\n",
    "        binary[binary>0] = 1\n",
    "        labels = skimage.morphology.label(binary)\n",
    "        labels_num = [len(labels[labels==each]) for each in np.unique(labels)]\n",
    "        rank = np.argsort(np.argsort(labels_num))\n",
    "        index = list(rank).index(len(rank)-2)\n",
    "        new_img = np.copy(img)\n",
    "        new_img[labels!=index] = 0\n",
    "        return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he_paths = glob.glob(\"./data/predictions/*.png\")\n",
    "test = []\n",
    "for he_path in tqdm_notebook(he_paths):\n",
    "    img = cv2.imread(he_path,0)\n",
    "    img = cv2.resize(img, (img.shape[1]//8, img.shape[0]//8))\n",
    "\n",
    "    splitted_img = split_label_dims_highres(img)\n",
    "\n",
    "    epithelium = np.uint8(splitted_img[:,:,0])\n",
    "    epithelium = np.int32(epithelium)\n",
    "    epithelium = skimage.morphology.label(epithelium)\n",
    "    epithelium = skimage.morphology.remove_small_objects(epithelium, 256)\n",
    "    epithelium = np.where(epithelium > 0, 2, 0)\n",
    "    test.append(epithelium.astype(\"int64\"))\n",
    "\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_labels(test, scale=(8,8,8), blending='additive')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from ipywidgets import interact\n",
    "\n",
    "trained_models = \"./trained_models\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the qptiff files from the directory and puts them into a processed file inside\n",
    "the directory path. In this case \"./data/66-4\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line will create a directory called \"processed_XX\" where XX is the selected resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.resize_qptiff_files(\"./data/multiplex\", \"32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the downsampled repository we will run an algorithm to remove dust and bubbles. Its output will be saved into \"processed_XX\" into a new directory called \"clean_dust_bubbles\". This was built this way to avoid overwritting files, allowing an easier resolution of errors if present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.remove_dustNbubbles(\"./data/66-4/processed_32\", image_resolution=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the path of the images you want to align this will create a list of directories with different content within it. Here are the most relevant ones:\n",
    "\n",
    "-  \"TA\" image mask form which the alignment is performed. The mask should be very clear without holes as mentioned by CODA authors.\n",
    "-  \"registered\" stores the global registered images\n",
    "-  \"elastic\" stores the elastic registered images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Run matlab script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.alignment_report(\"./data/66-4\", 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can choose over all the trained models (\"trained_model\" if this directory is empty run the training pipeline to generate a new ML model) saved to predict over a specific set of images. Therefore we need to include also the path from were we will be making the predictions registered, elastic, original etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_folder = \"\"\n",
    "\n",
    "@interact\n",
    "def show_files(files=next(os.walk(\"./trained_models\"))[1]):\n",
    "    global selected_folder\n",
    "    selected_folder = files\n",
    "    print(\"Selected folder:\", selected_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three ways to predict depending on RAM resources:\n",
    "- predict_stack_untiled() -> Fastest if enough RAM available\n",
    "- predict_image_stack_tiled() -> Decent time, tiling problem very visible in some models\n",
    "- predict_image_stack_tiled_smoothed() -> Takes the longest but reduces the tiling effect significantly (also really high RAM dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.path.join(\"trained_models\", selected_folder, \"unet.h5\"), compile=False)\n",
    "utils.predict_stack_untiled(directory= \"./data/66-4/processed_32/clean_dust_bubbles/registered/elastic registration/*.*\", model=model, model_trained_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model(os.path.join(\"trained_models\", \"results_20240611_202952\", \"unet.h5\"), compile=False)\n",
    "# utils.predict_stack_tiled(directory= \"./data/66-4/processed_4/clean_dust_bubbles/registered/elastic registration/*.jpg\", model=model, model_trained_size=4096)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate a movie in the \"videos\" directory with a recording of the predicted 3D or the 2D depending on the requirements. \n",
    "\n",
    "If you want to inspect the model predictions visually, we recommend to run first 2D. If everything is ok then proceed with an execution of the 3D video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build 3D\n",
    "utils.generate_render(\"./data/66-4/processed_32/clean_dust_bubbles/registered/elastic registration/*.tif\"\n",
    "                      ,\"./data/predictions/*.png\"\n",
    "                      , record_video=False\n",
    "                      , format=\"3D\") # 2D or 3D # This setting only works if record_video is set to true"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

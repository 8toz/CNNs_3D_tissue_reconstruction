{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NAPARI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils    \n",
    "\n",
    "import napari\n",
    "import dask\n",
    "import dask.array as da\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from natsort import natsorted\n",
    "from napari_animation import Animation\n",
    "\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
    "\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_label_dims(img_path):\n",
    "    img = cv2.imread(img_path,0)\n",
    "    final_image = np.zeros_like(img)\n",
    "\n",
    "    for value in [1, 2, 3, 4]:\n",
    "        single_channel_img = np.where(img == value, 1, 0)\n",
    "        final_image = np.dstack((final_image, single_channel_img))\n",
    "\n",
    "\n",
    "    final_image = final_image[:, :, 1:]\n",
    "\n",
    "    return final_image\n",
    "\n",
    "# Sort just in case\n",
    "def import_series(_file_list):\n",
    "    \"\"\" \n",
    "    Import series of images as dask array\n",
    "    _file_list needs to be list of pathts to images that want to be merged.\n",
    "    check shape at the end.\n",
    "    \"\"\"\n",
    "    \n",
    "    # lazily read images\n",
    "    _out_array = []\n",
    "\n",
    "    for _file in _file_list:\n",
    "        _z_stack = dask.delayed(cv2.imread)(_file)\n",
    "        _out_array.append(_z_stack)\n",
    " \n",
    "    # determine shape and type from reference frame\n",
    "    _ref_array = _out_array[-1].compute()\n",
    "    _shape = np.shape(_ref_array)\n",
    "    _dtype = _ref_array.dtype\n",
    " \n",
    "    # convert delayed to dask arrays\n",
    "    _out_array = [da.from_delayed(i, shape= _shape, dtype= _dtype) for i in _out_array]\n",
    "   \n",
    "    # merge dask arrays\n",
    "    _out_array = da.stack(_out_array)\n",
    " \n",
    "    return _out_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the path of the files\n",
    "# Directory of files to be read, each file needs to be able to fit into ram on its own.\n",
    "# file_names = glob.glob(\"./data/66-4/processed_32/*.tif\")\n",
    "he_file_names = glob.glob(\"./data/66-4/processed_32/clean_dust_bubbles/registered/*.tif\")\n",
    "he_file_names = natsorted(he_file_names)\n",
    "#stack = import_series(he_file_names)\n",
    "\n",
    "\n",
    "# predictions = glob.glob(\"./data/predictions/*.png\")\n",
    "# predictions = natsorted(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import skimage\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "prediction_paths = glob.glob(\"./data/predictions/*.png\")\n",
    "\n",
    "labels_to_plot = []\n",
    "for path in tqdm_notebook(prediction_paths):\n",
    "    #img = cv2.imread(path, 0)\n",
    "\n",
    "    img = split_label_dims(path)\n",
    "    img = img[:,:,0]\n",
    "    img = skimage.morphology.label(img)\n",
    "    img = skimage.morphology.remove_small_objects(img, 128)\n",
    "    labels_to_plot.append(img > 0)\n",
    "    \n",
    "\n",
    "labels_to_plot = np.array(labels_to_plot)\n",
    "\n",
    "stroma = []\n",
    "for path in tqdm_notebook(prediction_paths):\n",
    "    #img = cv2.imread(path, 0)\n",
    "\n",
    "    img = split_label_dims(path)\n",
    "    img = img[:,:,2]\n",
    "    stroma.append(img > 0)\n",
    "    \n",
    "\n",
    "stroma = np.array(stroma)\n",
    "\n",
    "fat = []\n",
    "for path in tqdm_notebook(prediction_paths):\n",
    "    #img = cv2.imread(path, 0)\n",
    "\n",
    "    img = split_label_dims(path)\n",
    "    img = img[:,:,3]\n",
    "    fat.append(img > 0)\n",
    "    \n",
    "\n",
    "fat = np.array(fat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_stack = []\n",
    "for _file in predictions:\n",
    "    img = cv2.imread(_file, 0)\n",
    "    predictions_stack.append(img.astype(\"int64\"))\n",
    "    #predictions_stack.append(split_label_dims(_file))\n",
    "\n",
    "predictions_stack = np.array(predictions_stack)\n",
    "\n",
    "\n",
    "he_img = []\n",
    "for _file in he_file_names:\n",
    "    img = cv2.imread(_file)\n",
    "    pad_image = utils._image_operations.white_pad_image(img, 128)\n",
    "    he_img.append(pad_image)\n",
    "\n",
    "he_img = np.array(he_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted images and labels should have the same shape\n",
    "assert predictions_stack.shape == he_img.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_to_plot.nbytes*1E-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at more things at the same time\n",
    "viewer = napari.Viewer()\n",
    "#viewer.add_image(predictions, channel_axis=3, name=['epithelium', 'blood_vessels', \"stroma\", \"adipocytes\"])\n",
    "#viewer.add_image(he_img, scale=(20,8,8))\n",
    "viewer.add_image(labels_to_plot, scale=(20,8,8), colormap=\"magenta\")\n",
    "viewer.add_image(stroma, scale=(20,8,8), colormap=\"cyan\")\n",
    "viewer.add_image(fat, scale=(20,8,8), colormap=\"yellow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Registration animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO activate labels with a nice opacity setting to get a smooth video\n",
    "# TODO fine tune the parameters to get a better video, now it goes a bit fast and not fluid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = Animation(viewer)\n",
    "viewer.update_console({\"animation\": animation})\n",
    "viewer.layers[-1].visible = False\n",
    "viewer.dims.current_step = (0, 0, 0)\n",
    "animation.capture_keyframe(steps=1)\n",
    "viewer.dims.current_step = (100, 0, 0)\n",
    "animation.capture_keyframe(steps=120)\n",
    "animation.animate(\"./videos/animate2D_32.mp4\", canvas_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animation = Animation(viewer)\n",
    "viewer.layers[-1].visible = True\n",
    "viewer.dims.ndisplay = 3\n",
    "viewer.camera.angles = (0.0, 0.0, 0.0)\n",
    "animation.capture_keyframe()\n",
    "viewer.camera.angles = (0.0, 180.0, 0.0)\n",
    "animation.capture_keyframe(steps=120)\n",
    "viewer.camera.angles = (0.0, 360.0, 0.0)\n",
    "animation.capture_keyframe(steps=120)\n",
    "animation.animate('./videos/test3D_32.mov', canvas_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unaligned = glob.glob(\"./data/66-4/processed_32/*.tif\")\n",
    "unaligned = natsorted(unaligned)\n",
    "\n",
    "preprocessed = glob.glob(\"./data/66-4/processed_32/clean_dust_bubbles/*.tif\")\n",
    "preprocessed = natsorted(preprocessed)\n",
    "\n",
    "global_transf = glob.glob(\"./data/66-4/processed_32/clean_dust_bubbles/registered/*.tif\")\n",
    "global_transf = natsorted(global_transf)\n",
    "\n",
    "elastic_transf = glob.glob(\"./data/66-4/processed_32/clean_dust_bubbles/registered/elastic registration/*.tif\")\n",
    "elastic_transf = natsorted(elastic_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread(global_transf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unaligned_stack = []\n",
    "# for _file in unaligned:\n",
    "#     img = cv2.imread(_file)\n",
    "#     img = cv2.resize(img, (test.shape[1], test.shape[0]))\n",
    "#     pad_image = utils._image_operations.white_pad_image(img, 128)\n",
    "#     unaligned_stack.append(pad_image)\n",
    "\n",
    "# unaligned_stack = np.array(unaligned_stack)\n",
    "\n",
    "\n",
    "# preprocessed_stack = []\n",
    "# for _file in preprocessed:\n",
    "#     img = cv2.imread(_file)\n",
    "#     img = cv2.resize(img, (test.shape[1], test.shape[0]))\n",
    "#     pad_image = utils._image_operations.white_pad_image(img, 128)\n",
    "#     preprocessed_stack.append(pad_image)\n",
    "\n",
    "# preprocessed_stack = np.array(preprocessed_stack)\n",
    "\n",
    "# global_stack = []\n",
    "# for _file in global_transf:\n",
    "#     img = cv2.imread(_file)\n",
    "#     pad_image = utils._image_operations.white_pad_image(img, 128)\n",
    "#     global_stack.append(pad_image)\n",
    "\n",
    "# global_stack = np.array(global_stack)\n",
    "\n",
    "\n",
    "elastic_stack = []\n",
    "for _file in elastic_transf:\n",
    "    img = cv2.imread(_file)\n",
    "    pad_image = utils._image_operations.white_pad_image(img, 128)\n",
    "    elastic_stack.append(pad_image)\n",
    "\n",
    "elastic_stack = np.array(elastic_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "# viewer.add_image(unaligned_stack, scale=(50,8,8))\n",
    "# viewer.add_image(preprocessed_stack, scale=(50,8,8))\n",
    "# viewer.add_image(global_stack, scale=(50,8,8))\n",
    "viewer.add_image(elastic_stack, scale=(50,8,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick zarr exploiting way, might not always work\n",
    "# file_path = r\"D:\\ERK_large_set\\ss_to_MEKi\\cytoring_labels.tif\"\n",
    "# img = da.from_zarr(tifffile.imread(file_path, aszarr=True))\n",
    "# #%%\n",
    "# # reshape to be able to split channels\n",
    "# shape = np.shape(img)\n",
    "# img = img.rechunk((1, shape[-3],shape[-2], shape[-1]))\n",
    "# #%%\n",
    "# # view image using napari\n",
    "# #view = img.swapaxes(0,1)\n",
    "# napari.view_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import utils._file_operations\n",
    "\n",
    "\n",
    "# utils._file_operations.create_folder(\"./data/66-4/reshaped_images\")\n",
    "\n",
    "\n",
    "# check for average image heigh and width\n",
    "# height = [] \n",
    "# width = []\n",
    "# for file in file_names:\n",
    "#     img = cv2.imread(file)\n",
    "#     height.append(img.shape[0])\n",
    "#     width.append(img.shape[1])\n",
    "\n",
    "# avg_height = np.round(sum(height)/len(height),0)\n",
    "# avg_width = np.round(sum(width)/len(width),0)\n",
    "\n",
    "# for i, file in enumerate(file_names):\n",
    "#   img = cv2.imread(file)\n",
    "#   reshaped = cv2.resize(img, (int(avg_height), int(avg_width)), interpolation= cv2.INTER_LINEAR)\n",
    "#   cv2.imwrite(os.path.join(\"./data/66-4/reshaped_images\",\"HE_\"+str(i)+\".tif\"), reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

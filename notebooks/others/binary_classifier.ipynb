{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import pandas as pd\n",
    "import os\n",
    "import utils\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from patchify import patchify, unpatchify\n",
    "from tensorflow.keras.models import load_model\n",
    "from ipywidgets import interact\n",
    "\n",
    "from matplotlib.lines import Line2D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = glob.glob(\"./data/final_images/train/masks/*.png\")\n",
    "for mask in masks:\n",
    "    img = cv2.imread(mask, 0)\n",
    "    print(np.unique(img))\n",
    "    binary_mask = np.where(img == 1, 1, 0)\n",
    "    #cv2.imwrite(mask, binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = glob.glob(\"./data/final_images/validation/masks/*.png\")\n",
    "for mask in masks:\n",
    "    img = cv2.imread(mask, 0)\n",
    "    print(np.unique(img))\n",
    "    binary_mask = np.where(img == 1, 1, 0)\n",
    "    #cv2.imwrite(mask, binary_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = glob.glob(\"./data/final_images/test/masks/*.png\")\n",
    "for mask in masks:\n",
    "    img = cv2.imread(mask, 0)\n",
    "    print(np.unique(img))\n",
    "    binary_mask = np.where(img == 1, 1, 0)\n",
    "    #cv2.imwrite(mask, binary_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dont touch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import utils._file_operations\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import keras\n",
    "from keras.losses import categorical_crossentropy, binary_crossentropy\n",
    "from keras.utils import to_categorical\n",
    "from keras.metrics import MeanIoU\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "def categorical_focal_loss(gamma=2.0, alpha=0.25):\n",
    "    \"\"\"\n",
    "    Implementation of Focal Loss from the paper in multiclass classification\n",
    "    Formula:\n",
    "        loss = -alpha*((1-p)^gamma)*log(p)\n",
    "    Parameters:\n",
    "        alpha -- the same as wighting factor in balanced cross entropy\n",
    "        gamma -- focusing parameter for modulating factor (1-p)\n",
    "    Default value:\n",
    "        gamma -- 2.0 as mentioned in the paper\n",
    "        alpha -- 0.25 as mentioned in the paper\n",
    "    \"\"\"\n",
    "    def focal_loss(y_true, y_pred):\n",
    "        # Define epsilon so that the backpropagation will not result in NaN\n",
    "        # for 0 divisor case\n",
    "        epsilon = K.epsilon()\n",
    "        # Add the epsilon to prediction value\n",
    "        #y_pred = y_pred + epsilon\n",
    "        # Clip the prediction value\n",
    "        y_pred = K.clip(y_pred, epsilon, 1.0-epsilon)\n",
    "        # Calculate cross entropy\n",
    "        cross_entropy = -y_true*K.log(y_pred)\n",
    "        # Calculate weight that consists of  modulating factor and weighting factor\n",
    "        weight = alpha * y_true * K.pow((1-y_pred), gamma)\n",
    "        # Calculate focal loss\n",
    "        loss = weight * cross_entropy\n",
    "        # Sum the losses in mini_batch\n",
    "        loss = K.sum(loss, axis=1)\n",
    "        return loss\n",
    "    \n",
    "    return focal_loss\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f*y_pred_f)\n",
    "    return (2.0 * intersection + 1.0)/(K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def jacard_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f*y_pred_f)\n",
    "    return (intersection + 1.0)/(K.sum(y_true_f) + K.sum(y_pred_f) - intersection + 1.0)\n",
    "\n",
    "def jacard_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -jacard_coef(y_true, y_pred)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    return 0.5 * tf.keras.losses.binary_crossentropy(y_true, y_pred) - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "\n",
    "def unet_model(n_classes=1, IMG_HEIGHT=256, IMG_WIDTH=256, IMG_CHANNELS=3):\n",
    "\n",
    "    inputs = Input((None, None, IMG_CHANNELS))\n",
    "    #s = Lambda(lambda x: x / 255)(inputs)   #No need for this if we normalize our inputs beforehand\n",
    "    s = inputs\n",
    "\n",
    "    #Contraction path\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
    "    \n",
    "    #Expansive path \n",
    "    u6 = Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def focal_loss(gamma=2., alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        y_true = tf.convert_to_tensor(y_true, dtype=tf.float32)\n",
    "        y_pred = tf.convert_to_tensor(y_pred, dtype=tf.float32)\n",
    "\n",
    "        alpha_t = y_true * alpha + (tf.ones_like(y_true) - y_true) * (1 - alpha)\n",
    "        p_t = y_true * y_pred + (tf.ones_like(y_true) - y_true) * (tf.ones_like(y_true) - y_pred) + tf.keras.backend.epsilon()\n",
    "        fl = - alpha_t * tf.keras.backend.pow((tf.ones_like(y_true) - p_t), gamma) * tf.keras.backend.log(p_t)\n",
    "        return tf.keras.backend.mean(fl)\n",
    "    return focal_loss_fixed\n",
    "\n",
    "def prepare_image_set(directory):\n",
    "    \"\"\"\n",
    "    Given a directory preprocess the images and returns an X, y set\n",
    "    \"\"\"\n",
    "    #Capture training image info as a list\n",
    "    train_images = []\n",
    "\n",
    "    for img_path in glob.glob(os.path.join(directory, \"images\", \"*.png\")):\n",
    "        img = cv2.imread(img_path, cv2.COLOR_BGR2RGB)       \n",
    "        train_images.append(img)\n",
    "        \n",
    "    #Convert list to array for machine learning processing        \n",
    "    train_images = np.array(train_images)\n",
    "\n",
    "    #Capture mask/label info as a list\n",
    "    train_masks = [] \n",
    "\n",
    "    for mask_path in glob.glob(os.path.join(directory, \"masks\", \"*.png\")):\n",
    "        mask = cv2.imread(mask_path, 0)       \n",
    "        train_masks.append(mask)\n",
    "       \n",
    "\n",
    "    train_masks = np.array(train_masks)\n",
    "    # Normalize images\n",
    "    train_images = train_images/255.0\n",
    "\n",
    "    return train_images, train_masks\n",
    "\n",
    "\n",
    "def train_model(TRAIN_CONFIG):\n",
    "\n",
    "    utils._file_operations.create_folder(os.path.join(\"./trained_models\", TRAIN_CONFIG[\"results_folder\"]))\n",
    "\n",
    "    \n",
    "    X_train, y_train = prepare_image_set(TRAIN_CONFIG[\"training_path\"])\n",
    "    X_val, y_val = prepare_image_set(TRAIN_CONFIG[\"validation_path\"])\n",
    "    X_test, y_test = prepare_image_set(TRAIN_CONFIG[\"test_path\"])\n",
    "\n",
    "    print(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background \n",
    "\n",
    "    # Convert masks to categorical (should have shape (height, width, n_classes))\n",
    "    y_train_cat = np.float32(y_train)\n",
    "    y_val_cat = np.float32(y_val)\n",
    "    y_test_cat = np.float32(y_test)\n",
    "\n",
    "    # Check that the shape of all images is the same\n",
    "    assert X_train.shape[1] == X_val.shape[1] == X_test.shape[1]\n",
    "\n",
    "\n",
    "    IMG_HEIGHT = X_train.shape[1]\n",
    "    IMG_WIDTH  = X_train.shape[2]\n",
    "    IMG_CHANNELS = X_train.shape[3]\n",
    "\n",
    "    def get_model(network):\n",
    "        return unet_model(n_classes=TRAIN_CONFIG[\"n_classes\"], IMG_HEIGHT=IMG_HEIGHT, IMG_WIDTH=IMG_WIDTH, IMG_CHANNELS=IMG_CHANNELS)\n",
    "    \n",
    "    keras.utils.set_random_seed(32)\n",
    "    model = get_model(network = \"unet\")\n",
    "    \n",
    "    optimizer = keras.optimizers.Adam(learning_rate=TRAIN_CONFIG[\"learning_rate\"])\n",
    "    callback_ES = keras.callbacks.EarlyStopping(monitor='val_loss', patience=TRAIN_CONFIG[\"early_stopping_patience\"], restore_best_weights=True)\n",
    "    callback_LR = keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=TRAIN_CONFIG[\"lr_mod_factor\"], patience=TRAIN_CONFIG[\"lr_on_plateau_patience\"])\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss=focal_loss(), metrics=['accuracy', jacard_coef])\n",
    "    #model.compile(optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy', jacard_coef])\n",
    "\n",
    "    #model.summary()\n",
    "\n",
    "    #If starting with pre-trained weights. \n",
    "    #model.load_weights('???.hdf5')\n",
    "\n",
    "    start = datetime.now()\n",
    "    history = model.fit(X_train, y_train_cat, \n",
    "                        batch_size = TRAIN_CONFIG[\"batch_size\"], \n",
    "                        verbose=TRAIN_CONFIG[\"verbose\"], \n",
    "                        epochs=TRAIN_CONFIG[\"epochs\"], \n",
    "                        validation_data=(X_val, y_val_cat), \n",
    "                        callbacks=[callback_ES, callback_LR],\n",
    "                        # sample_weight=class_weights,\n",
    "                        shuffle=True)\n",
    "    stop = datetime.now()\n",
    "    execution_time = stop - start\n",
    "    print(f\"The Neural Network training took {execution_time}\")\n",
    "\n",
    "\n",
    "    # Model evaluation\n",
    "    _, acc, jaq = model.evaluate(X_test, y_test_cat, batch_size=8)\n",
    "    print(\"Accuracy is = \", (acc * 100.0), \"%\")\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test, batch_size=6)\n",
    "    y_pred_argmax = np.argmax(y_pred, axis=3)\n",
    "    # y_pred_argmax_unstacked = utils.unstack_labels(y_pred_argmax)\n",
    "    # y_test_unstacked = utils.unstack_labels(y_test)\n",
    "\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test.reshape(-1), y_pred_argmax.reshape(-1))\n",
    "    clf_report = classification_report(y_test.reshape(-1), y_pred_argmax.reshape(-1), output_dict=True)\n",
    "\n",
    "\n",
    "    print(classification_report(y_test.reshape(-1), y_pred_argmax.reshape(-1)))\n",
    "\n",
    "\n",
    "    IOU_keras = MeanIoU(num_classes=TRAIN_CONFIG[\"n_classes\"])  \n",
    "    IOU_keras.update_state(y_test, y_pred_argmax)\n",
    "    mean_IoU = IOU_keras.result().numpy()\n",
    "    print(\"Mean IoU =\", mean_IoU)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = [\"unet\", \"deeplabv3\", \"attention_unet\", \"attention_resunet\", \"unet_pluplus\"]\n",
    "\n",
    "execution_time = pd.Timestamp.now()\n",
    "TRAIN_CONFIG = {\n",
    "    \"training_path\":\"./data/final_images/train\",\n",
    "    \"validation_path\":\"./data/final_images/validation\", \n",
    "    \"test_path\":\"./data/final_images/test\",\n",
    "    \"network\":\"unet\",\n",
    "    \"save_model\":True,\n",
    "    \"downscaling_factor\":32, #If specified you can keep track of performance in the excel file\n",
    "    \"n_classes\":1,\n",
    "    \"batch_size\": 16,\n",
    "    \"epochs\": 100,\n",
    "    \"validation_split\":0.1,\n",
    "    \"test_split\":0.1,\n",
    "    \"learning_rate\":0.001,\n",
    "    \"early_stopping_patience\":30,\n",
    "    \"lr_on_plateau_patience\":10,\n",
    "    \"lr_mod_factor\":0.1,\n",
    "    \"execution_time\": execution_time.strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    \"results_folder\": \"results_\" + execution_time.strftime(\"%Y%m%d_%H%M%S\"),\n",
    "    \"verbose\": 1 if os.name==\"nt\" else 0 # dissables verbose if we run on Snellius\n",
    "}\n",
    "\n",
    "train_model(TRAIN_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

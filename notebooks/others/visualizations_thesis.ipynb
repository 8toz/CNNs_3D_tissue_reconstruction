{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Read the images using OpenCV\n",
    "he = cv2.imread(\"./lateral_view.png\")\n",
    "mult = cv2.imread(\"./lateral_view2.png\")\n",
    "third_image = cv2.imread(\"./3D_he_opacity.png\")  # Replace with your third image file path\n",
    "\n",
    "# Convert the images from BGR to RGB\n",
    "he_rgb = cv2.cvtColor(he, cv2.COLOR_BGR2RGB)\n",
    "mult_rgb = cv2.cvtColor(mult, cv2.COLOR_BGR2RGB)\n",
    "third_image_rgb = cv2.cvtColor(third_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create a figure with GridSpec\n",
    "fig = plt.figure(figsize=(15, 7))\n",
    "gs = GridSpec(2, 2, height_ratios=[1, 1], width_ratios=[1, 1])\n",
    "\n",
    "# Create the axes for each image\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax2 = fig.add_subplot(gs[1, 1])\n",
    "ax3 = fig.add_subplot(gs[0, :])  # Span the first row across two columns\n",
    "\n",
    "# Display the images\n",
    "ax1.imshow(he_rgb)\n",
    "ax2.imshow(mult_rgb)\n",
    "ax3.imshow(third_image_rgb)\n",
    "\n",
    "# Remove axis ticks and labels\n",
    "ax1.axis(\"off\")\n",
    "ax2.axis(\"off\")\n",
    "ax3.axis(\"off\")\n",
    "\n",
    "# Adjust layout to make images close to each other\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "# Save the plot with 600 dpi\n",
    "plt.savefig(\"output_images.png\", dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the images using OpenCV\n",
    "he = cv2.imread(\"./side_view_multiplex_he.png\")\n",
    "mult = cv2.imread(\"./side_view_HE_multiplex_2.png\")\n",
    "\n",
    "# Convert the images from BGR to RGB\n",
    "he_rgb = cv2.cvtColor(he, cv2.COLOR_BGR2RGB)\n",
    "mult_rgb = cv2.cvtColor(mult, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 10))\n",
    "\n",
    "# Display the images\n",
    "ax1.imshow(he_rgb)\n",
    "ax2.imshow(mult_rgb)\n",
    "\n",
    "# Remove axis ticks and labels\n",
    "ax1.axis(\"off\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "# Adjust layout to make images close to each other\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.05)\n",
    "\n",
    "# Save the plot with 600 dpi\n",
    "plt.savefig(\"output_images.png\", dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the images using OpenCV\n",
    "he = cv2.imread(\"./new_he3D.png\")\n",
    "mult = cv2.imread(\"./misc/final_3D_multiplex.png\")\n",
    "\n",
    "# Convert the images from BGR to RGB\n",
    "he_rgb = cv2.cvtColor(he, cv2.COLOR_BGR2RGB)\n",
    "he_rgb = cv2.resize(he_rgb, (mult_rgb.shape[1], mult_rgb.shape[0]))\n",
    "mult_rgb = cv2.cvtColor(mult, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "# Display the images\n",
    "ax1.imshow(he_rgb)\n",
    "ax2.imshow(mult_rgb)\n",
    "\n",
    "# Remove axis ticks and labels\n",
    "ax1.axis(\"off\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "# Adjust layout to make images close to each other\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "# Save the plot with 600 dpi\n",
    "plt.savefig(\"output_images.png\", dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the images using OpenCV\n",
    "he = cv2.imread(\"final_he_multiplex_combined.png\")\n",
    "mult = cv2.imread(\"side_view_multiplex_he.png\")\n",
    "print(he.shape)\n",
    "print(mult.shape)\n",
    "\n",
    "# Convert the images from BGR to RGB\n",
    "he_rgb = cv2.cvtColor(he, cv2.COLOR_BGR2RGB)\n",
    "mult_rgb = cv2.cvtColor(mult, cv2.COLOR_BGR2RGB)\n",
    "mult_rgb = cv2.copyMakeBorder(mult_rgb, top=(mult.shape[1]-he.shape[1])//2, bottom=(mult.shape[1]-he.shape[1])//2, left=0, right=0, borderType=cv2.BORDER_CONSTANT)\n",
    "mult_rgb = cv2.resize(mult_rgb, (he.shape[1], he.shape[0]))\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 10))\n",
    "\n",
    "# Display the images\n",
    "ax1.imshow(he_rgb)\n",
    "ax2.imshow(mult_rgb)\n",
    "\n",
    "\n",
    "# Remove axis ticks and labels\n",
    "ax1.axis(\"off\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "\n",
    "# Adjust layout to make images close to each other\n",
    "plt.subplots_adjust(wspace=0.05)\n",
    "\n",
    "# Save the plot with 600 dpi\n",
    "plt.savefig(\"output_images.png\", dpi=600, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "\n",
    "mossaic_mask = glob.glob(\"./data/mossaics/training_mossaics/mask_sample_*.png\")[1]\n",
    "mossaic_img =  glob.glob(\"./data/mossaics/training_mossaics/rgb_sample_*.png\")[1]\n",
    "img  = cv2.imread(mossaic_img)\n",
    "mask = cv2.imread(mossaic_mask, 0)\n",
    "\n",
    "colors = [\"black\", \"green\", \"red\", \"blue\", \"yellow\"]\n",
    "labels = [\"Background\", \"Epithelium\", \"Blood Vessels\", \"Stroma\", \"Adipocytes\"]\n",
    "imin = 0\n",
    "imax = len(colors)\n",
    "cmap = plt.cm.colors.ListedColormap(colors)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 6), dpi=600)\n",
    "gs = gridspec.GridSpec(2, 2, height_ratios=[1, 10], width_ratios=[1, 1])\n",
    "gs.update(wspace=0.02, hspace=0.05)\n",
    "\n",
    "ax_legend = fig.add_subplot(gs[0, :])\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax2 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "ax_legend.axis(\"off\")\n",
    "\n",
    "ax1.imshow(img)\n",
    "ax2.imshow(mask, cmap=cmap, vmin=imin, vmax=imax, interpolation=\"nearest\")\n",
    "\n",
    "# Draw vertical lines and add labels\n",
    "for ax in [ax1, ax2]:\n",
    "    width = img.shape[1]  # Assuming both images have the same width\n",
    "    for x in range(256, width, 256):\n",
    "        ax.axvline(x=x, color='red', linestyle='--', linewidth=1)\n",
    "        \n",
    "for ax in [ax1, ax2]:\n",
    "    width = img.shape[1]  # Assuming both images have the same width\n",
    "    for y in range(256, width, 256):\n",
    "        ax.axhline(y=y, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "ax1.axis(\"off\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "patches = [mpatches.Patch(color=colors[i], label=labels[i]) for i in range(len(colors))]\n",
    "ax_legend.legend(handles=patches, loc='center', ncol=len(colors))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "import napari\n",
    "# Uncomment when using dask \n",
    "# import dask\n",
    "# import dask.array as da\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "from natsort import natsorted\n",
    "from napari_animation import Animation\n",
    "\n",
    "os.environ[\"OPENCV_IO_MAX_IMAGE_PIXELS\"] = pow(2,40).__str__()\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Store images\n",
    "he_file_names = glob.glob(\"./data/66-4/processed_4/clean_dust_bubbles/registered/elastic registration/*.jpg\")\n",
    "he_file_names = natsorted(he_file_names)\n",
    "\n",
    "predictions = glob.glob(\"./data/bck_predictions/*.png\")\n",
    "predictions = natsorted(predictions)\n",
    "\n",
    "\n",
    "\n",
    "he_img = []\n",
    "for _file in tqdm_notebook(he_file_names):\n",
    "    img = cv2.imread(_file)\n",
    "    \n",
    "    # IMPORTANT\n",
    "    # In order to match the shape of the predictions we must \n",
    "    # pad the image the same way as it is done in the predictions\n",
    "    pad_image = utils._image_operations.white_pad_image(img, 1024)\n",
    "    pad_image = cv2.resize(pad_image, (pad_image.shape[1]//4,pad_image.shape[0]//4))\n",
    "    he_img.append(pad_image)\n",
    "\n",
    "he_img = np.array(he_img)\n",
    "\n",
    "predictions_stack = []\n",
    "for _file in tqdm_notebook(predictions):\n",
    "    img = cv2.imread(_file, 0)\n",
    "    img = cv2.resize(img, (img.shape[1]//4,img.shape[0]//4))\n",
    "    # Change color of labels\n",
    "    img = np.where(img == 2, 10, img)\n",
    "    img = np.where(img == 1, 12, img)\n",
    "    img = np.where(img == 3, 16, img)\n",
    "    img = np.where(img == 4, 9, img)\n",
    "    \n",
    "\n",
    "    predictions_stack.append(img.astype(\"int64\"))\n",
    "\n",
    "predictions_stack = np.array(predictions_stack)\n",
    "\n",
    "# We check the shape to see if the padding applied to predictions is \n",
    "# The same as for the H&E\n",
    "assert predictions_stack.shape == he_img.shape[:-1]\n",
    "# Initialize the viewer\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(he_img, scale=(20,4,4))\n",
    "viewer.add_labels(predictions_stack, scale=(20,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = cv2.imread(glob.glob(\"./data/bck_predictions/*253*.png\")[0],0)\n",
    "\n",
    "img = cv2.imread(glob.glob(\"./data/66-4/processed_4/clean_dust_bubbles/registered/elastic registration/*253*.jpg\")[0])\n",
    "\n",
    "labels = np.where(labels == 1, 6, labels)\n",
    "labels = np.where(labels == 2, 10, labels)\n",
    "labels = np.where(labels == 3, 16, labels)\n",
    "labels = np.where(labels == 4, 9, labels)\n",
    "\n",
    "labels = labels[np.newaxis, :] \n",
    "img = img[np.newaxis, :]\n",
    "\n",
    "import napari\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(img, scale=(8,8,8))\n",
    "viewer.add_labels(labels, scale=(8,8,8), blending='translucent', opacity=0.67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "\n",
    "# Assuming you have a list of image file paths\n",
    "image_paths = [\n",
    "    'check_preds_1.png', 'check_preds_2.png', 'check_preds_3.png',\n",
    "    'check_preds_4.png', 'check_preds_5.png', 'check_preds_6.png',\n",
    "    'check_preds_7.png', 'check_preds_8.png', 'check_preds_9.png'\n",
    "]\n",
    "\n",
    "\n",
    "# Check if all images exist\n",
    "for img_path in image_paths:\n",
    "    if not os.path.exists(img_path):\n",
    "        raise FileNotFoundError(f\"Image {img_path} not found!\")\n",
    "\n",
    "# Create a 3x3 grid to display the images\n",
    "fig, axs = plt.subplots(3, 3, figsize=(40, 25))\n",
    "\n",
    "# Plot each image in the grid\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    img = mpimg.imread(image_paths[i])\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')  # Hide the axes\n",
    "\n",
    "\n",
    "# Adjust layout to reduce spacing between rows and columns\n",
    "plt.subplots_adjust(wspace=0.01, hspace=0.01, top=0.92)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure if needed\n",
    "# plt.savefig('grid.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
